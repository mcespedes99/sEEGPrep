bids_dir: '/path/to/bids_dir'
output_dir: '/path/to/output_dir'

# Resources
local_scratch: '/tmp'
local_scratch_env: 'SLURM_TMPDIR'

#enable printing debug statements during parsing -- disable if generating dag visualization
debug: False

derivatives: False #will search in bids/derivatives if True; can also be path(s) to derivatives datasets

#list of analysis levels in the bids app
analysis_levels: &analysis_levels
 - participant


#mapping from analysis_level to set of target rules or files
targets_by_analysis_level:
  participant:
    - ''  # if '', then the first rule is run

#this configures the pybids grabber - create an entry for each type of input you want to grab
# indexed by name of input
#   dictionary for each input is passed directly to pybids get()
#    https://bids-standard.github.io/pybids/generated/bids.layout.BIDSLayout.html#bids.layout.BIDSLayout.get

pybids_inputs:
  edf:
    filters:
      # datatype: 'ieeg'
      # suffix: 'ieeg'
      extension: '.edf'
    wildcards:
      - subject
      - session
      - task
      - run
      - acquisition
  
  events:
    filters:
      suffix: 'events'
      extension: '.tsv'
    wildcards:
      - subject
      - session
      - task
      - run
      - acquisition
  
  channels:
    filters:
      suffix: 'channels'
      extension: '.tsv'
    wildcards:
      - subject
      - session
      - task
      - run
      - acquisition
  
  electrodes:
    filters:
      suffix: 'electrodes'
      extension: '.tsv'
    wildcards:
      - subject
      - session
      - task
      - run
      - acquisition
  
  json:
    filters:
      suffix: 'ieeg'
      extension: '.json'
    wildcards:
      - subject
      - session
      - task
      - run
      - acquisition

  parc:
    filters:
      suffix: 'orig'
      extension: '.mgz'
    wildcards:
      - subject
      - session
      - acquisition
      - task
      - run
      - acquisition
    custom_path: /scratch/mcesped/Results/registration/subject_space/bids/sub-{subject}/anat/sub-{subject}_desc-synthsegcortparc_dseg.nii.gz

# ---------------- Pipeline parameters-------------------
# Event: [label or index, 'duration' or 'n_samples', amount as seconds or int]
event: ['awake trigger', 'duration', 240] # 4 min 'awake trigger'
event_label: 'event' # name of column where events are described ('trial_type', 'event', etc.)

# 1. Parameters for downsampling step:
# (1.a) Target sampling rate
# Default: 200 Hz
target_srate: 1024

# 2. Parameters for detrending step:
# (2.a) Detrend method 
# Options: 'LinearDetrend','HighPass' (default), 'Demean'
detrend_method: 'HighPass'

# (2.b) Transition band of high pass filter used in detrending step (if selected)
highpass: [0.1, 0.2]

# 3. Parameters for PLI attenuation
# (3.a) Power line interference removal method
# Options: 'Cleanline', 'Zapline', 'NotchFilter' (default), 'PLIremoval'
methodPLI: 'Cleanline'

# (3.b) Electrical grid fundamental frequency
# Default: 60 Hz  
lineFreq: 60

# (3.c) Bandwidth for Notch filter (TODO) or Cleanline
# Note: in 'Cleanline', the bandwidth represents the frequency range 
# (around the theoretical fundamental and harmonic frequencies) in which
# to search for possible peaks associated with line noise. 
# Default: 4 (ex: if lineFreq=60, the range would go from 58 to 62)
bandwidth: 8

# (3.d) Number of harmonics to remove when using Notch Filter
# Default: 1 (only removes fundamental frequency)
n_harmonics: 1

# 4. Parameters for region identification step
# (4.1) Boolean to discard signals from electrodes located in white matter or 
# 'unknown' region
# Default: True (discards the signals)
discard_wm_un: True
reference_edf: 'bipolar' # 'unipolar' or 'bipolar'
vol_version: True 


# 4. Parameter for regions identification and rereferencing step 
# (4.1) Column names in tsv file with electrodes information
# Format: [{type of channel}, {channel label}, {x position}, {y position}, {z position}, {group}]
# Default: ['type', 'label', 'x', 'y', 'z', 'group'] or None (both options are equivalent)
tsv_cols: ['type', 'label', 'x', 'y', 'z', 'orig_group']


# Color table required to asign labels for each value in the parcellation file
colortable: /scratch/mcesped/code/MNI_Registration/registration_workflow/resources/tpl-MNI305/atlas/FreeSurferColorLUT.tsv

# QC
bids_validator_flags: '--ignoreSubjectConsistency'

#-------------------------------BIDS APP Configuration---------------------------
#this configures the options to save the BIDSLayout
# by default, database is not saved (uncomment to save)
# NOTE: pybids_db_dir must be an absolute path
# pybids_db_dir: '/path/to/db_dir' # Leave blank if you do not wish to use this
# pybids_db_reset: False # Change this to true to update the database

#configuration for the command-line parameters to make available
# passed on the argparse add_argument()
parse_args:

#---  core BIDS-app options --- (do not modify below)

  bids_dir:
    help: The directory with the input dataset formatted according
          to the BIDS standard.

  output_dir:
    help: The directory where the output files
          should be stored. If you are running group level analysis
          this folder should be prepopulated with the results of the
          participant level analysis.

  analysis_level:
    help: Level of the analysis that will be performed.
    choices: *analysis_levels

  --participant_label:
    help: The label(s) of the participant(s) that should be analyzed. The label
          corresponds to sub-<participant_label> from the BIDS spec
          (so it does not include "sub-"). If this parameter is not
          provided all subjects should be analyzed. Multiple
          participants can be specified with a space separated list.
    nargs: '+'

  --exclude_participant_label:
    help: The label(s) of the participant(s) that should be excluded. The label
          corresponds to sub-<participant_label> from the BIDS spec
          (so it does not include "sub-"). If this parameter is not
          provided all subjects should be analyzed. Multiple
          participants can be specified with a space separated list.
    nargs: '+'

  --derivatives:
    help: 'Path(s) to a derivatives dataset, for folder(s) that contains multiple derivatives datasets (default: %(default)s) '
    default: False
    nargs: '+'

  --run_all:
    help: 'Run complete preprocessing pipeline: downsampling, cleaning and rereferencing.'
    default: false
    action: store_true

  --epoch:
    help: 'Extract epochs from a given edf file.'
    default: false
    action: store_true

  --downsample:
    help: 'Downsample a given edf file.'
    default: false
    action: store_true

  --filter:
    help: 'Filter a given edf file (detrending and noise detection).'
    default: false
    action: store_true
  
  --rereference:
    help: 'Rereference a given unipolar edf file to bipolar.'
    default: false
    action: store_true

  --PLI_rej:
    help: 'Power Line Noise rejection given an edf file.'
    default: false
    action: store_true

  --regions_id:
    help: 'Identify regional location of electrodes given edf file and discard white matter and unknown categories.'
    default: false
    action: store_true

  --graham:
    help: 'Use containers on compute canada graham.'
    default: false
    action: store_true

  --event_label:
    help: 'Name of column in events.tsv where the events labels are defined.'
    default: 'event'

#singularity containers
singularity:
    graham:
      bids_validator: '/scratch/mcesped/containers/validator_latest.sif'
    docker:
      bids_validator: 'docker://bids/validator:latest'
